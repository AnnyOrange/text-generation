01/19/2024 11:52:37 - INFO - __main__ - ***** Running training *****
01/19/2024 11:52:37 - INFO - __main__ -   Num examples = 11
01/19/2024 11:52:37 - INFO - __main__ -   Num Epochs = 5
01/19/2024 11:52:37 - INFO - __main__ -   Instantaneous batch size per device = 1
01/19/2024 11:52:37 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4
01/19/2024 11:52:37 - INFO - __main__ -   Gradient Accumulation steps = 4
01/19/2024 11:52:37 - INFO - __main__ -   Total optimization steps = 15
Steps:   0%|                                                                                                                                                      | 0/15 [00:00<?, ?it/s]C:\Users\30661\.conda\envs\torchgpu\lib\site-packages\diffusers\configuration_utils.py:139: FutureWarning: Accessing config attribute `num_train_timesteps` directly via 'DDPMScheduler' object attribute is deprecated. Please access 'num_train_timesteps' over 'DDPMScheduler's config object instead, e.g. 'scheduler.config.num_train_timesteps'.
  deprecate("direct config name access", "1.0.0", deprecation_message, standard_warn=False)
We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.
You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (2), or the `sep_token_id` (None), and your input is not padded.
Steps:   0%|                                                                                                                            | 0/15 [00:04<?, ?it/s, lr=5e-6, step_loss=0.116]01/19/2024 11:52:41 - INFO - __main__ - Running validation...
 Generating 1 images with prompt: Transform the text in the image into Anny's style with a white background..
{'image_encoder'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                                         `text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["id2label"]` will be overriden.
`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["bos_token_id"]` will be overriden.                       | 0/7 [00:00<?, ?it/s]
`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["eos_token_id"]` will be overriden.
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of timbrooks/instruct-pix2pix.
                                                                                                                                                                                         {'rescale_betas_zero_snr', 'timestep_spacing'} was not found in config. Values will be initialized to default values.
Loaded scheduler as EulerAncestralDiscreteScheduler from `scheduler` subfolder of timbrooks/instruct-pix2pix.                                              | 1/7 [00:01<00:09,  1.58s/it]
{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.
Loaded vae as AutoencoderKL from `vae` subfolder of timbrooks/instruct-pix2pix.
                                                                                                                                                                                         Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of timbrooks/instruct-pix2pix.
Loading pipeline components...:  43%|██████████████████████████████████████████████████▌                                                                   | 3/7 [00:02<00:02,  1.75it/s]Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of timbrooks/instruct-pix2pix.
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of timbrooks/instruct-pix2pix.███████▍                                                  | 4/7 [00:02<00:01,  2.43it/s]
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:02<00:00,  2.46it/s]
Traceback (most recent call last):0%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:02<00:00,  3.23it/s]
  File "D:\AI\text-re\text-generation\finetune_pix2pix_text.py", line 1272, in <module>
    main()
  File "D:\AI\text-re\text-generation\finetune_pix2pix_text.py", line 1145, in main
    init_image = download_image(args.val_image_url)
  File "D:\AI\text-re\text-generation\finetune_pix2pix_text.py", line 458, in download_image
    image = PIL.Image.open(requests.get(url, stream=True).raw)
  File "C:\Users\30661\.conda\envs\torchgpu\lib\site-packages\requests\api.py", line 76, in get
    return request('get', url, params=params, **kwargs)
  File "C:\Users\30661\.conda\envs\torchgpu\lib\site-packages\requests\api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\Users\30661\.conda\envs\torchgpu\lib\site-packages\requests\sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\30661\.conda\envs\torchgpu\lib\site-packages\requests\sessions.py", line 677, in send
    history = [resp for resp in gen]
  File "C:\Users\30661\.conda\envs\torchgpu\lib\site-packages\requests\sessions.py", line 677, in <listcomp>
    history = [resp for resp in gen]
  File "C:\Users\30661\.conda\envs\torchgpu\lib\site-packages\requests\sessions.py", line 237, in resolve_redirects
    resp = self.send(
  File "C:\Users\30661\.conda\envs\torchgpu\lib\site-packages\requests\sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\30661\.conda\envs\torchgpu\lib\site-packages\requests\adapters.py", line 439, in send
    resp = conn.urlopen(
  File "C:\Users\30661\.conda\envs\torchgpu\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\Users\30661\.conda\envs\torchgpu\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\Users\30661\.conda\envs\torchgpu\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Users\30661\.conda\envs\torchgpu\lib\http\client.py", line 1377, in getresponse
    response.begin()
  File "C:\Users\30661\.conda\envs\torchgpu\lib\http\client.py", line 320, in begin
    version, status, reason = self._read_status()
  File "C:\Users\30661\.conda\envs\torchgpu\lib\http\client.py", line 281, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Users\30661\.conda\envs\torchgpu\lib\socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "C:\Users\30661\.conda\envs\torchgpu\lib\ssl.py", line 1242, in recv_into
    return self.read(nbytes, buffer)
  File "C:\Users\30661\.conda\envs\torchgpu\lib\ssl.py", line 1100, in read
    return self._sslobj.read(len, buffer)
KeyboardInterrupt