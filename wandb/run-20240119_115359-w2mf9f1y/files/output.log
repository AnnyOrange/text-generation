01/19/2024 11:54:05 - INFO - __main__ - ***** Running training *****
01/19/2024 11:54:05 - INFO - __main__ -   Num examples = 11
01/19/2024 11:54:05 - INFO - __main__ -   Num Epochs = 5
01/19/2024 11:54:05 - INFO - __main__ -   Instantaneous batch size per device = 1
01/19/2024 11:54:05 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4
01/19/2024 11:54:05 - INFO - __main__ -   Gradient Accumulation steps = 4
01/19/2024 11:54:05 - INFO - __main__ -   Total optimization steps = 15
Steps:   0%|                                                                                                                                                      | 0/15 [00:00<?, ?it/s]C:\Users\30661\.conda\envs\torchgpu\lib\site-packages\diffusers\configuration_utils.py:139: FutureWarning: Accessing config attribute `num_train_timesteps` directly via 'DDPMScheduler' object attribute is deprecated. Please access 'num_train_timesteps' over 'DDPMScheduler's config object instead, e.g. 'scheduler.config.num_train_timesteps'.
  deprecate("direct config name access", "1.0.0", deprecation_message, standard_warn=False)
We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.
You may ignore this warning if your `pad_token_id` (0) is identical to the `bos_token_id` (0), `eos_token_id` (2), or the `sep_token_id` (None), and your input is not padded.
Steps:   0%|                                                                                                                            | 0/15 [00:04<?, ?it/s, lr=5e-6, step_loss=0.116]01/19/2024 11:54:09 - INFO - __main__ - Running validation...
 Generating 1 images with prompt: 灏嗗浘鍍忎腑鐨勬枃鏈浆鎹负琛屼功鏍峰紡锛岃儗鏅负鐧借壊.
{'image_encoder'} was not found in config. Values will be initialized to default values.
                                                                                                                                                                                         {'timestep_spacing', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.
Loaded scheduler as EulerAncestralDiscreteScheduler from `scheduler` subfolder of timbrooks/instruct-pix2pix.                                                      | 0/7 [00:00<?, ?it/s]
Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of timbrooks/instruct-pix2pix.
                                                                                                                                                                                         {'scaling_factor', 'force_upcast'} was not found in config. Values will be initialized to default values.
Loaded vae as AutoencoderKL from `vae` subfolder of timbrooks/instruct-pix2pix.                                                                            | 2/7 [00:00<00:01,  3.00it/s]
                                                                                                                                                                                         `text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["id2label"]` will be overriden.
`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["bos_token_id"]` will be overriden.               | 3/7 [00:01<00:01,  2.83it/s]
`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config["eos_token_id"]` will be overriden.
Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of timbrooks/instruct-pix2pix.
                                                                                                                                                                                         Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of timbrooks/instruct-pix2pix.
Loaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of timbrooks/instruct-pix2pix.█████████████▍                                                  | 4/7 [00:02<00:02,  1.28it/s]
Loading pipeline components...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:02<00:00,  2.68it/s]
Token indices sequence length is longer than the specified maximum sequence length for this model (89 > 77). Running this sequence through the model will result in indexing errors
The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['负鐧借壊']
validate0 1
Steps:   0%|                                                                                                                            | 0/15 [00:20<?, ?it/s, lr=5e-6, step_loss=0.064]01/19/2024 11:54:25 - INFO - __main__ - Running validation...
